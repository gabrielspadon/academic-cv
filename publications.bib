@InProceedings{spadon2018complex,
  author    = {Spadon, Gabriel and Scabora, Lucas C. and Araujo, Marcus V. S. and Oliveir, Paulo H. and Machado, Bruno B. and Sousa, Elaine P. M. and Traina, Caetano and Rodrigues, Jose F.},
  booktitle = {Information Technology - New Generations},
  title     = {Complex-Network Tools to Understand the Behavior of Criminality in Urban Areas},
  year      = {2018},
  address   = {Cham},
  editor    = {Latifi, Shahram},
  pages     = {493-500},
  publisher = {Springer International Publishing},
  abstract  = {Complex networks are nowadays employed in several applications. Modeling urban street networks is one of them, and in particular to analyze criminal aspects of a city. Several research groups have focused on such application, but until now, there is a lack of a well-defined methodology for employing complex networks in a whole crime analysis process, i.e. from data preparation to a deep analysis of criminal communities. Furthermore, the ``toolset'' available for those works is not complete enough, also lacking techniques to maintain up-to-date, complete crime datasets and proper assessment measures. In this sense, we propose a threefold methodology for employing complex networks in the detection of highly criminal areas within a city. Our methodology comprises three tasks: (i) Mapping of Urban Crimes; (ii) Criminal Community Identification; and (iii) Crime Analysis. Moreover, it provides a proper set of assessment measures for analyzing intrinsic criminality of communities, especially when considering different crime types. We show our methodology by applying it to a real crime dataset from the city of San Francisco-CA, USA. The results confirm its effectiveness to identify and analyze high criminality areas within a city. Hence, our contributions provide a basis for further developments on complex networks applied to crime analysis.},
  isbn      = {978-3-319-54978-1},
  keywords  = {Complex Networks, Crime Analysis, Urban Areas, Criminal Communities, Data Preparation},
}

@InProceedings{scabora2019g,
  author    = {Scabora, Lucas de Carvalho and Spadon, Gabriel and Rodrigues, Lucas Santiago and Cazzolato, Mirela Teixeira and Araújo, Marcus Vinicius dos Santos and Sousa, Elaine Parros Machado de and Traina, Agma Juci Machado and Rodrigues Junior, José Fernando and Traina Junior, Caetano},
  booktitle = {Dataset Showcase Workshop},
  title     = {G-franc: a dataset of criminal activities mapped as a complex network in a relational dbms},
  year      = {2019},
  publisher = {Special Database Commission (SBBD) of the Brazilian Computer Society (SBC)},
  journal   = {Proceedings Companion},
  keywords  = {Criminal Activities, Complex Networks, Relational DBMS, Dataset, G-franc},
}

@Article{spadon2017identifying,
  author   = {Gabriel Spadon and Gabriel Gimenes and Jose F. Rodrigues-Jr},
  journal  = {Procedia Computer Science},
  title    = {Identifying Urban Inconsistencies via Street Networks},
  year     = {2017},
  issn     = {1877-0509},
  note     = {International Conference on Computational Science, ICCS 2017, 12-14 June 2017, Zurich, Switzerland},
  pages    = {18-27},
  volume   = {108},
  abstract = {Street networks are complex networks that represent the topology and geometry of cities; as so, they can be used to solve problems related to ill-designed urban structures. This application, in real urban scenarios, has been the focus of several types of research, from cities characterization to transportation enhancement. Nevertheless, these works lack a clear and in-depth methodology to characterize the urban space by means of complex networks. Aided by topo-geometrical measures from street networks, we present a methodology to identify what we call urban inconsistencies, which are characterized by low-access regions containing nodes (crossing streets) that lack efficient access from or to other regions in a city. We devised algorithms capable of preprocessing and analyzing street networks, pointing to existing mobility problems in a city. We identify inconsistencies that pertain to a given node where a facility of interest is currently placed; the results introduce ways to assist in the urban planning and design processes. Our techniques are discussed through the analysis of a real-world city. In a real context, the methods provide basis for analyzing and improving the placement of facilities.},
  doi      = {doi.org/10.1016/j.procs.2017.05.103},
  keywords = {Complex Networks, Urban Design, Planning Inconsistencies, Mobility, Street Networks},
  url      = {www.sciencedirect.com/science/article/pii/S1877050917306555},
}

@Article{spadon2017behavioral,
  author   = {Gabriel Spadon and Lucas C. Scabora and Paulo H. Oliveira and Marcus V.S. Araujo and Bruno B. Machado and Elaine P.M. Sousa and Caetano Traina-Jr and Jose F. Rodrigues-Jr},
  journal  = {Procedia Computer Science},
  title    = {Behavioral Characterization of Criminality Spread in Cities},
  year     = {2017},
  issn     = {1877-0509},
  note     = {International Conference on Computational Science, ICCS 2017, 12-14 June 2017, Zurich, Switzerland},
  pages    = {2537-2541},
  volume   = {108},
  abstract = {Complex networks are commonly used to model urban street networks, which allows aiding the analysis of criminal activities in cities. Despite several works focusing on such application, there is a lack of a clear methodology focused in the analysis of crime behavior. In this sense, we propose a methodology for employing complex networks in the analysis of criminality spread within criminal areas of a city. Here, we evaluate synthetic cases of crime propagation concerning real criminal data from the North American city of San Francisco — CA. Our results confirm the effectiveness of our methodology in analyzing the crime behavior by means of criminality spread. Hence, this paper renders further development and planning on public safety in cities.},
  doi      = {doi.org/10.1016/j.procs.2017.05.118},
  keywords = {Complex Networks, Criminality Analysis, Crime Spread, Public Safety, Urban Street Networks},
  url      = {www.sciencedirect.com/science/article/pii/S187705091730683X},
}

@InProceedings{marques2017restify,
  author    = {Marques, Luiz F. and Correia, Ronaldo C. M. and Spadon, Gabriel and Eler, Danilo M. and Olivete-Jr, Celso and Garcia, Rogério E.},
  booktitle = {2017 12th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Data bases available through APIs using Restify: Characteristics, programming models, and benchmarks},
  year      = {2017},
  month     = {June},
  pages     = {1-6},
  abstract  = {The volume of data exchanged by computer networks is gradually increasing over time, which provides the need for performance and interoperability between different platforms and systems. In this line, there are several studies dedicated to service-oriented software architectures and resource consumption models. However, a few of them are focused on the development of generic tools for the dynamic creation of data provisioning services. This article presents the analysis of a tool called Restify, which is able to dynamically create web services to provide an online database as a service. Restify achieved the system interoperability requirements regarding heterogeneous operations, programming languages, and server infrastructures. As a result, we observed that the performance of this tool was comparable, if not better, than other evaluated web services, such as REST and SOAP. Finally, Restify excels by behaving like an interface tool, allowing the management and integration of multiple online system tools with various relational databases.},
  doi       = {10.23919/CISTI.2017.7975715},
  keywords  = {APIs, Restify, Web Services, Database as a Service, System Interoperability},
}

@InProceedings{almeida2017moba,
  author    = {Almeida, Carlos E. M. and Correia, Ronaldo C. M. and Eler, Danilo M. and Olivete-Jr, Celso and Garci, Rogério E. and Scabora, Lucas C. and Spadon, Gabriel},
  booktitle = {2017 12th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Prediction of winners in MOBA games},
  year      = {2017},
  month     = {June},
  pages     = {1-6},
  abstract  = {Multiplayer Online Battle Arena (MOBA) games are very popular in the current eSport scenario, being highlighted in several competitions around the world. However, the domain of knowledge contained in these games is large, which makes it difficult to discover and predict the course of a match. The present work proposes the application of classification algorithms to determine the team with more chances to win a match. Two classifications procedures were used, one based on the composition of heroes in each team and another considering the duration of the match. The experiments were performed on data collected from 123,326 matches of Dota 2, showing that it was possible to achieve approximately 77% accuracy. The results demonstrate the effectiveness of the application when using techniques assisted by computers, and when using the methodology described in championships or other similar games that require the definition of strategies.},
  doi       = {10.23919/CISTI.2017.7975774},
 keywords     = {MOBA Games, Winner Prediction, Classification Algorithms, eSports, Data Mining}
}

@InProceedings{caldeira2017mineraskill,
  author    = {Caldeira, Dayane C. M. F. and Correia, Ronaldo C. M. and Spadon, Gabriel and Eler, Danilo M. and Olivete-Jr, Celso and Garcia, Rogério E.},
  booktitle = {2017 12th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Data mining on LinkedIn data to define professional profile via MineraSkill methodology},
  year      = {2017},
  month     = {June},
  pages     = {1-6},
  abstract  = {Social networks are of significant analytical interest. This is because their data are generated in great quantity, and intermittently, besides that, the data are from a wide variety, and it is widely available to users. Through such data, it is desired to extract knowledge or information that can be used in decision-making activities. In this context, we have identified the lack of methods that apply data mining techniques to the task of analyzing the professional profile of employees. The aim of such analyses is to detect competencies that are of greater interest by being more required and also, to identify their associative relations. Thus, this work introduces MineraSkill methodology that deals with methods to infer the desired profile of a candidate for a job vacancy. In order to do so, we use keyword detection via natural language processing techniques; which are related to others by inferring their association rules. The results are presented in the form of a case study, which analyzed data from LinkedIn, demonstrating the potential of the methodology in indicating trending competencies that are required together.},
  doi       = {10.23919/CISTI.2017.7975730},
  keywords  = {Data Mining, Professional Profile, LinkedIn, Natural Language Processing, MineraSkill},
}

@PhdThesis{spadon2017phdthesis,
  author   = {Gabriel Spadon},
  title    = {Characterization of mobility patterns and collective behavior through the analytical processing of real-world complex networks},
  doi      = {10.11606/D.55.2017.TDE-29092017-100417},
  url      = {www.semanticscholar.org/paper/e61cd442c3c47c9b85ae2c65140c3542429a4968},
  abstract = {Cities are complex systems of transportation and social activity; their structure can be used to model urban street networks i.e. complex network that represents the geometry of a city allowing analytical activities for data-driven decision-making. The geometry of a city holds intrinsic information that can support activities related to the analysis of the urban scenario; of higher importance is the use of such information to enhance the quality of life of its inhabitants and/or to understand the dynamics of an urban center. Several of these analytical processes lacks in-depth methodologies to analyze crime patterns and ill-designed urban structures, which can provide for public safety and urban design. Consequently, it is our goal to provide means for the structural and topological analysis of highly criminal regions of cities represented as complex networks, and for the identification of urban planning inconsistencies that point to regions that lack access from/to points of interest in a city. In this regard, we devised a set of algebraic and algorithmic procedures that are capable of revealing patterns and provide for data comprehension. More specifically, we introduced pre-processing techniques to transform georeferenced electronic maps into graph representations of cities; we used metric-based and epidemic processes to understand the dynamics of cities in what refers to criminality; finally, we introduced a novel set of formalisms and operations based on set theory to identify design flaws concerning access in urban centers. Our results refer to approaches to preprocess and prepare maps in the form of urban street networks; to the analyses of crimes based on their spatial disposition; to the development of a model to describe criminal activities; and, to the advance of a concept based on critical problems in the urban design.},
  school   = {Universidade de São Paulo},
  year     = {2017},
  keywords     = {Mobility Patterns, Collective Behavior, Complex Networks, Urban Street Networks, Crime Analysis}
}

@InProceedings{machado2018smartphone,
  author    = {Machado, Bruno Brandoli and Spadon, Gabriel and Arruda, Mauro S. and Goncalves, Wesley N. and Carvalho, Andre C. P. L. F. and Rodrigues-Jr, Jose F.},
  booktitle = {Proceedings of the 33rd Annual ACM Symposium on Applied Computing},
  title     = {A smartphone application to measure the quality of pest control spraying machines via image analysis},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {956–963},
  publisher = {Association for Computing Machinery},
  series    = {SAC '18},
  abstract  = {The need for higher agricultural productivity has demanded the intensive use of pesticides. However, their correct use depends on assessment methods that can accurately predict how well the pesticides' spraying covered the intended crop region. Some methods have been proposed in the literature, but their high cost and low portability harm their widespread use. This paper proposes and experimentally evaluates a new methodology based on the use of a smartphone-based mobile application, named DropLeaf. Experiments performed using DropLeaf showed that, in addition to its versatility, it can predict with high accuracy the pesticide spraying. DropLeaf is a five-fold image-processing methodology based on: (i) color space conversion; (ii) threshold noise removal; (iii) convolutional operations of dilation and erosion; (iv) detection of contour markers in the water-sensitive card; and, (v) identification of droplets via the marker-controlled watershed transformation. The authors performed successful experiments over two case studies, the first using a set of synthetic cards and the second using a real-world crop. The proposed tool can be broadly used by farmers equipped with conventional mobile phones, improving the use of pesticides with health, environmental and financial benefits.},
  doi       = {10.1145/3167132.3167237},
  isbn      = {9781450351911},
  keywords  = {Pesticide Spraying Analysis, Image Processing, Mobile Application, Agricultural Productivity, Deposition Analysis},
  location  = {Pau, France},
  numpages  = {8},
  url       = {doi.org/10.1145/3167132.3167237},
}

@InProceedings{gomes2017software,
  author    = {de Andrade Gomes, Pedro Henrique and Garcia, Rogério Eduardo and Spadon, Gabriel and Eler, Danilo Medeiros and Olivete, Celso and Messias Correia, Ronaldo Celso},
  booktitle = {2017 IEEE Frontiers in Education Conference (FIE)},
  title     = {Teaching software quality via source code inspection tool},
  doi       = {10.1109/FIE.2017.8190658},
  pages     = {1-8},
  abstract  = {Software Quality Assurance is a sub-process that ensures that developed software meets and complies with defined or standardized quality specifications. Focusing on source code, there are characteristics that can be used to evaluate the quality. Introductory courses must encourage freshmen students to improve internal quality of their source code, but only as sophomore they have contact with Software Engineering concepts, including Quality Assurance. In this paper we present a tool to source code quality evaluation aimed at supporting students to improve their source code and, consequently, their programming skills. The proposed tool uses quality reports (available to professional environment integrate with software repositories) to analyze students' source code and provide a feedback about the student coding. The proposed tool run locally, with few computational resources. In addition, we proposed the methodology to use the proposed tool: it consists of challenging students to perform a set of maintenance tasks in a controlled environment. We prepared a source code by introducing common defects, what decreases the quality of source code, and ask to students to perform maintenance tasks in order to both eliminate the introduced defects and introduce new features. After each modification, the students must evaluate their code using the proposed tool to obtain a feedback about quality of source code. To evaluate the approach and the tool, we created a survey and applied to students and the teacher. As a result, we show the benefits of using the proposed tool to both teachers and students perspectives. The results are positive to enhance the teaching-learning Software Quality Assurance to Software Engineering students.},
  keywords     = {Software Quality Assurance, Source Code Inspection, Teaching Methodology, Programming Skills, Software Engineering Education},
  month     = {Oct},
  year      = {2017},
}

@InProceedings{spadon2016combined,
  author    = {Spadon, Gabriel and de Andrade Gomes, Pedro Henrique and Correia, Ronaldo Celso Messias and Olivete, Celso and Eler, Danilo Medeiros and Garcia, Rogério Eduardo},
  booktitle = {2016 IEEE Frontiers in Education Conference (FIE)},
  title     = {Combined Methodology for Theoretical Computing},
  year      = {2016},
  month     = {Oct},
  pages     = {1-7},
  abstract  = {Theoretical Computer Science area (TCS) stands out by being an important study field, and it is composed by Formal Languages and Automata Theory (FLA), Computer Science Theory (CST), and Theory of Compilers (TC). This area is responsible for introducing the beginnings of the Computer Science through formalisms - which represent a set of methods, techniques, or rules that describe the solution to a problem with restrictions - and it has a substantial impact on the student's knowledge. Computer science theory is based on the understanding of computability and techniques to solve challenges, and to improve the teaching-learning process used to introduce these concepts we proposed a Combined Methodology for Theoretical Computing (CMTC). Our methodology is based on formalism development to ground the knowledge acquired during classes of FLA, CST, and TC, where students are introduced to Theoretical Computing during one year and a half. In each course, we applied the same methodology where each student used data structures, computer graphics, and algorithms to solve problems. We address this methodology to understand how much the incomprehension of formalisms is influenced by new concepts and its abstractions. Against this background, we demonstrate that the that CMTC has the aim to build knowledge and make the new concepts and formalisms concrete. Our results are based on statistical analysis from students' grades, where we could observe among other results, the correlation between the practical activities and the conceptual knowledge.},
  doi       = {10.1109/FIE.2016.7757574},
  keywords  = {Theoretical Computer Science, Formal Languages, Automata Theory, Teaching Methodology, Computer Science Education},
}

@InProceedings{spadon2015teaching,
  author    = {Spadon, Gabriel and Olivete, Celso and Messias Correia, Ronaldo Celso and Garcia, Rogério Eduardo},
  booktitle = {2015 IEEE Frontiers in Education Conference (FIE)},
  title     = {Teaching-learning methodology for formal languages and automata theory},
  year      = {2015},
  month     = {Oct},
  pages     = {1-7},
  abstract  = {Formal languages and automata (FLA) theory have fundamental relevance to the base of knowledge in the computer science area, especially focusing on scientific education. Usually presented by a discipline, the teaching-learning process of FLA is characterized by the high level of abstraction, and it is considered difficult due to the complexity of language formalisms. As support for the learning process, tools have been used to simulate language formalisms. However, the simulation is not enough to reinforce the construction of an abstract concept. In this paper, we present an FLA teaching-learning methodology based on the development of simulators as an approach to clarify the formalism for the students. Through developing their simulators, students are exposed to the data structure and algorithms to handle the formalism. Consequently, students have the opportunity to make the concept concrete.},
  doi       = {10.1109/FIE.2015.7344185},
  keywords     = {Formal Language and Automata Theory, Teaching Methodology, Learning Tool, Cognitive Load, Education}
}

@InProceedings{spadon2015simulation,
  author    = {Spadon, Gabriel and Messias Correia, Ronaldo Celso and Garcia, Rogério Eduardo and Olivete, Celso},
  booktitle = {2015 10th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Simulation and analysis applied on virtualization to build Hadoop clusters},
  year      = {2015},
  month     = {June},
  pages     = {1-7},
  abstract  = {The data growth enhances the need of a method and paradigms responsible to deal with high scalability, reliability and fault tolerance in large amounts of data. Big Data is a framework capable of dealing with this need. This research makes usage of Apache Hadoop, and a Virtual Private Server (VPS) to analyze the performance through benchmark tests executed on locally, geographically distributed, and centralized Hadoop computational layout. The result from the simulations metrics, and performance analyses are compared to real servers and introduce an alternative model implemented with a tunnel protocol that enhance the processing power of the cluster.},
  doi       = {10.1109/CISTI.2015.7170466},
  issn      = {2166-0727},
  keywords     = {Big Data, Hadoop, Scalability, Virtual Private Server, Benchmark Testing}
}

@InProceedings{santana2015scalable,
  author    = {Santana, Vagner José and de Souza, Gabriel Spadon and Messias Correia, Ronaldo Celso and Garcia, Rogério Eduardo and Medeiros Eler, Danilo and Olivete, Celso},
  booktitle = {2015 10th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Scalable information system using event oriented programming and NoSQL},
  doi       = {10.1109/CISTI.2015.7170465},
  pages     = {1-6},
  abstract  = {One of many challenges in a web information systems is the capability of staying stable and available as the number of users and requests increase rapidly, what we call scalability. This paper provides a model based on development of events-oriented applications, non-blocking in the environment Node.JS with the non-relational database model (MongoDB), preparing to establish scalability and a comparison with a traditional model (relational database (MySQL), HTTP Apache server and PHP language). The results obtained reveal that the proposed model is more efficient (response time of six to eight faster) than the comparative model, can be used in production environments with development quality, performance improvement and scalability.},
  issn      = {2166-0727},
  keywords     = {Scalable Information System, Event-Oriented Programming, NoSQL, Node.JS, MongoDB},
  month     = {June},
  year      = {2015},
}

@InProceedings{correia2018teaching,
  author    = {Correia, Ronaldo C. M. and Spadon, Gabriel and Eler, Danilo M. and Olivete, Celso and Garcia, Rogério E.},
  booktitle = {Information Technology - New Generations},
  title     = {Teaching Distributed Systems Using Hadoop},
  year      = {2018},
  address   = {Cham},
  editor    = {Latifi, Shahram},
  pages     = {355-362},
  publisher = {Springer International Publishing},
  abstract  = {Databases and Distributed Systems have a fundamental relevance in Computer Science; they are usually presented in courses where the high-level of abstraction characterizes the teaching and learning processes. Consequently, the teaching method needs to evolve to fulfill the present requirements. Therefore, grounded in these concepts, the main goal of this paper is to introduce a teaching methodology via benchmark tests. Our methodology was conducted using the Hadoop framework, and it is innovative and proved effective. Our methods allow students to be exposed to complex data, system architecture, network infrastructure, trending technologies and algorithms. During the courses, students analyzed the performance of some computational architectures through benchmark tests on local and on the cloud. Along with this scenario, they evaluate the processing time of each architecture. As a result, our methodology proved to be a support learning method, which allows students to have contact with trending tools.},
  isbn      = {978-3-319-54978-1},
  keywords     = {Teaching Methodology, Distributed Systems, Hadoop, Benchmark Tests, Computer Science Education}
}

@InProceedings{spadon2018distance,
  author    = {Spadon, Gabriel and Machado, Bruno B. and Eler, Danilo M. and Rodrigues, Jose F.},
  booktitle = {Computational Science - ICCS 2018},
  title     = {A Distance-Based Tool-Set to Track Inconsistent Urban Structures Through Complex-Networks},
  editor    = {Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.},
  isbn      = {978-3-319-93698-7},
  pages     = {288-301},
  publisher = {Springer International Publishing},
  abstract  = {Complex networks can be used for modeling street meshes and urban agglomerates. With such a model, many aspects of a city can be investigated to promote a better quality of life to its citizens. Along these lines, this paper proposes a set of distance-based pattern-discovery algorithmic instruments to improve urban structures modeled as complex networks, detecting nodes that lack access from/to points of interest in a given city. Furthermore, we introduce a greedy algorithm that is able to recommend improvements to the structure of a city by suggesting where points of interest are to be placed. We contribute to a thorough process to deal with complex networks, including mathematical modeling and algorithmic innovation. The set of our contributions introduces a systematic manner to treat a recurrent problem of broad interest in cities.},
  address   = {Cham},
  year      = {2018},
  keywords     = {Complex Networks, Urban Structures, Distance-Based Analysis, Pattern Discovery, City Planning}
}

@Article{correia2018hadoop,
  author         = {Correia, Ronaldo Celso Messias and Spadon, Gabriel and De Andrade Gomes, Pedro Henrique and Eler, Danilo Medeiros and Garcia, Rogério Eduardo and Olivete Junior, Celso},
  journal        = {Information},
  title          = {Hadoop Cluster Deployment: A Methodological Approach},
  year           = {2018},
  issn           = {2078-2489},
  number         = {6},
  volume         = {9},
  abstract       = {For a long time, data has been treated as a general problem because it just represents fractions of an event without any relevant purpose. However, the last decade has been just about information and how to get it. Seeking meaning in data and trying to solve scalability problems, many frameworks have been developed to improve data storage and its analysis. As a framework, Hadoop was presented as a powerful tool to deal with large amounts of data. However, it still causes doubts about how to deal with its deployment and if there is any reliable method to compare the performance of distinct Hadoop clusters. This paper presents a methodology based on benchmark analysis to guide the Hadoop cluster deployment. The experiments employed The Apache Hadoop and the Hadoop distributions of Cloudera, Hortonworks, and MapR, analyzing the architectures on local and on clouding—using centralized and geographically distributed servers. The results show the methodology can be dynamically applied on a reliable comparison among different architectures. Additionally, the study suggests that the knowledge acquired can be used to improve the data analysis process by understanding the Hadoop architecture.},
  article-number = {131},
  doi            = {10.3390/info9060131},
  keywords       = {Hadoop Cluster, Deployment Methodology, Benchmark Analysis, Data Scalability, Distributed Computing},
  url            = {www.mdpi.com/2078-2489/9/6/131},
}

@InProceedings{spadon2018topological,
  author    = {Spadon, Gabriel and Gimenes, Gabriel and Rodrigues, Jose F.},
  booktitle = {Computational Science - ICCS 2018},
  title     = {Topological Street-Network Characterization Through Feature-Vector and Cluster Analysis},
  year      = {2018},
  address   = {Cham},
  editor    = {Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.},
  pages     = {274-287},
  publisher = {Springer International Publishing},
  abstract  = {Complex networks provide a means to describe cities through their street mesh, expressing characteristics that refer to the structure and organization of an urban zone. Although other studies have used complex networks to model street meshes, we observed a lack of methods to characterize the relationship between cities by using their topological features. Accordingly, this paper aims to describe interactions between cities by using vectors of topological features extracted from their street meshes represented as complex networks. The methodology of this study is based on the use of digital maps. Over the computational representation of such maps, we extract global complex-network features that embody the characteristics of the cities. These vectors allow for the use of multidimensional projection and clustering techniques, enabling a similarity-based comparison of the street meshes. We experiment with 645 cities from the Brazilian state of Sao Paulo. Our results show how the joint of global features describes urban indicators that are deep-rooted in the network's topology and how they reveal characteristics and similarities among sets of cities that are separated from each other.},
  isbn      = {978-3-319-93698-7},
  keywords     = {Topological Street-Network, Feature Vector Analysis, Cluster Analysis, Complex Networks, Urban Indicators}
}

@InProceedings{nesso2018rafiki,
  author    = {Nesso, Marcos R. and Cazzolato, Mirela T. and Scabora, Lucas C. and Oliveira, Paulo H. and Spadon, Gabriel and de Souza, Jessica A. and Oliveira, Willian D. and Chino, Daniel Y. T. and Rodrigues, Jose F. and Traina, Agma J. M. and Traina, Caetano},
  booktitle = {2018 IEEE 31st International Symposium on Computer-Based Medical Systems (CBMS)},
  title     = {RAFIKI: Retrieval-Based Application for Imaging and Knowledge Investigation},
  year      = {2018},
  month     = {June},
  pages     = {71-76},
  abstract  = {Medical exams, such as CT scans and mammograms, are obtained and stored every day in hospitals all over the world, including images, patient data, and medical reports. It is paramount to have tools and systems to improve computer-aided diagnoses based on such huge volumes of stored information. The Content-Based Image Retrieval (CBIR) is a powerful paradigm to help reaching such a goal, providing physicians with intelligent retrieval tools to present him/her with similar or complementary cases, in which visual characteristics improve textual data. Employing comparative inspection on previous cases, the physician can obtain a more comprehensive understanding of the case he/she is working on. Current hospital systems do not carry native CBIR functionalities yet, relying on add-on subsystems, which often do not adhere to the existing relational database infrastructures. In this work, we propose RAFIKI, a software prototype that extends the Relational Database Management System (RDBMS) PostgreSQL, providing native support for CBIR functionalities, modular extensibility, and seamless integration for data science tools, such as Python and R. We show the applicability of our system by evaluating three clinical scenarios, performing queries over a real-world image dataset of lung exams. Our results spot actual potential in promoting informed decision-making from the physician's perspective. Besides, the system exhibited a higher performance when compared to previous systems found in the literature. Moreover, RAFIKI contributes with a model to establish how to put together CBIR concepts and relational data, providing a powerful design for further development of theoretical and practical concepts and tools.},
  doi       = {10.1109/CBMS.2018.00020},
  issn      = {2372-9198},
  keywords     = {Content-Based Image Retrieval, Computer-Aided Diagnosis, Relational Database, Medical Imaging, RAFIKI}
}

@InProceedings{arruda2018recognition,
  author    = {de Arruda, Mauro dos Santos and Spadon, Gabriel and Rodrigues, Jose F and Gonçalves, Wesley Nunes and Machado, Bruno Brandoli},
  booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Recognition of Endangered Pantanal Animal Species using Deep Learning Methods},
  year      = {2018},
  month     = {July},
  pages     = {1-8},
  abstract  = {Pantanal is one of the most important biomes of the world, with a large number of wild animal species, some of them are in extinction. The automatic identification of wild animals is extremely important for the estimation of the species' population within Pantanal. However, digital processing techniques for the identification and tracking of species have faced great challenges due to clumsy light and pose conditions present in images taken in the wild. To overcome such problems, we propose a methodology that, by combining regular RGB images and thermal images, improves the identilication of species even in images taken in rough circumstances. We use the SLIC segmentation algorithm to identify the regions of the images where animals are present; after that, we apply convolutional neural networks to classify the identified regions according to eight possible animal species. We experiment on a real-world dataset composed of 1,600 images. Our results showed an average gain between 6% and 10% when compared to the method Fast R-CNN.},
  doi       = {10.1109/IJCNN.2018.8489369},
  issn      = {2161-4407},
  keywords     = {Endangered Species Recognition, Pantanal, Deep Learning, Convolutional Neural Networks, Image Segmentation}
}

@InProceedings{spadon2018computer,
  author       = {Gabriel Spadon and José F. Rodrigues},
  booktitle    = {Proceedings of the Poster Track of the Workshop on Big Social Data and Urban Computing co-located with BiDU 2018 at VLDB 2018, Rio de Janeiro, Brazil, August 31, 2018},
  title        = {Computer-assisted City Touring for Explorers},
  year         = {2018},
  organization = {CEUR Online Proceedings for Scientific Conferences and Workshops},
  abstract     = {The basic purpose of a map is to trace shortest paths between two locations in a city. However, this is not always what a user needs. Consider a tourist in an unknown city, he/she might want to trace routes to visit multiple landmarks while passing through the main streets of the city, possibly more than once through the same street. Such functionality is not yet available in online map services, which are prone to provide shortest paths that connect all landmarks. Rather, is of common interest a tour that puts together the most central streets (topologically speaking), minimizes the trajectory and, at the same time, passes through such landmarks. To cope with this problem, it is possible to investigate techniques of Center-Piece Subgraph, Absorbing Random Walk Centrality and Spanning Edge-Betweenness; such techniques can be used to find induced subgraphs that optimize centrality measures for a set of referential nodes or edges, i.e. landmarks or streets. The results shall be in the form of optimized algorithms, and how to integrate them into online systems. Studies in this line can succeed if they can guarantee timely scalability at the same time that they provide algorithms that produce tours (1) considering all the known destinations; (2) including the main streets of a city; and, (3) ensuring the shortest routes.},
  keywords     = {City Touring, Centrality Measures, Route Optimization, Urban Computing, Online Map Services},
  url          = {www.semanticscholar.org/paper/ece33d058bfe1572590ca07238d74bf3639401bd},
}

@Article{spadon2019detecting,
  author   = {Gabriel Spadon and Bruno Brandoli and Danilo M. Eler and Jose F. Rodrigues-Jr},
  journal  = {Journal of Computational Science},
  title    = {Detecting multi-scale distance-based inconsistencies in cities through complex-networks},
  year     = {2019},
  issn     = {1877-7503},
  pages    = {209-222},
  volume   = {30},
  abstract = {We propose an algebraic tool-set and related algorithms to track access problems not obviously observed in urban environments represented as street mashes. Our tool-set assumes that points of interest must be promptly accessible within the paths of a street network. Over that assumption, we introduce formalisms and computational tools to detect and evaluate access-related problems. The output of our methods, in the form of inconsistent nodes found in a given city, has the potential to assist the decision-making process regarding the positioning of resources, building of new services, and outlining the initial design of a city.},
  doi      = {doi.org/10.1016/j.jocs.2018.12.015},
  keywords = {Complex Networks, Urban Analysis, Network Analysis, Distance-Based Inconsistencies, Access Problems},
  url      = {www.sciencedirect.com/science/article/pii/S1877750318309955},
}

@InProceedings{spadon2018caracterizaccao,
  author    = {Gabriel Spadon and Lucas C. Scabora and Marcos R. Nesso-Jr and Caetano Traina-Jr and Jose F. Rodrigues-Jr},
  booktitle = {SBBD},
  title     = {Caracterização Topológica de Redes Viárias por Meio da Análise de Vetores de Características e Técnicas de Agrupamento},
  year      = {2018},
  pages     = {157-168},
  publisher = {Sociedade Brasileira de Computação - SBC},
  volume    = {18},
  abstract  = {As redes complexas contribuem para a pesquisa computacional por sua capacidade de projetar sistemas modelados por vértices e arestas. Eles fornecem meios para descrever estruturas urbanas por meio das malhas viárias, expressando predicados que se referem ao fluxo e ao transporte em zonas urbanas. Este trabalho tem o objetivo de descrever as interações entre diferentes cidades usando seus vetores de características pela análise de informações viárias e das métricas inerentes aos seus elementos. Propõe-se uma análise baseada no uso de mapas digitais, pois permitem abordagens para modelagem de dados e extração de características que suportam atividades analíticas. Os resultados deste trabalho são baseados na análise de 645 cidades, que formam o estado brasileiro de São Paulo; tais resultados demonstram como características extraídas por métricas de grafos descrevem indicadores urbanos que estão enraizados na topologia da rede, e como podem revelar diferenças entre cidades distintas.},
  doi       = {10.5753/sbbd.2018.22227},
  keywords  = {Topological Characterization, Road Networks, Feature Vectors, Clustering Techniques, Urban Analysis},
  url       = {www.semanticscholar.org/paper/648d5b4d5f47d59a3961e60d16d2a032780e731f},
  venue     = {Brazilian Symposium on Databases},
}

@Article{scabora2018cutting,
  author       = {L. C. Scabora and Paulo H. Oliveira and Gabriel Spadon and D. S. Kaster and José F. Rodrigues and A. Traina and C. Júnior},
  journal      = {Journal of Information and Data Management},
  title        = {Cutting-edge Relational Graph Data Management with Edge-k: From One to Multiple Edges in the Same Row},
  year         = {2018},
  issn         = {2178-7107},
  number       = {1},
  pages        = {20-20},
  volume       = {9},
  abstract     = {Relational Database Management Systems (RDBMSs) are widely employed in several applications, including those that deal with data modeled as graphs. Existing solutions store every edge in a distinct row in the edge table, however, for most cases, such modeling does not provide adequate performance. In this work, we propose Edge-k, a technique to group the vertex neighborhood into a reduced number of rows in a table through additional columns that stores up to k edges per row. The technique provides a better table organization and reduces both table size and query processing time. We evaluate Edge-k table management for insert, update, delete and bulkload operations, and compare the query processing performance both with the conventional edge table — adopted by the existing frameworks — and with the Neo4j graph database. Experiments using Single-Source Shortest Path (SSSP) queries reveal that our new proposal approach always outperforms the conventional edge table as well as it was faster than Neo4j for the first iterations, being slightly slower than Neo4j only for iterations after having loaded the whole graph from disk to memory. It was able to reach a speedup of 66% over a representative real dataset, with an average reduction of up to 58% in our tests. The average speedup over synthetic datasets was up to 54%. Edge-k was also the best one when performing graph degree distribution queries. Moreover, the Edge-k table obtained a processing time reduction of 70% for bulkload operations, despite having an overhead of 50% for individual insert, update and delete operations. Finally, Edge-k advances the state of the art for graph data management within relational database systems.},
  doi          = {10.5753/jidm.2018.1634},
  journaltitle = {Journal of Information and Data Management},
  keywords     = {Relational Database Management, Graph Data Management, Edge-k, Query Optimization, Table Organization},
  publisher    = {Sociedade Brasileira de Computacao - SB},
  url          = {www.semanticscholar.org/paper/bdfd1151a29d5a3219a4ffe907d67f32c4708012},
}

@InProceedings{ferreira2018comparative,
  author    = {Ferreira, Lucas D and Spadon, Gabriel and Carvalho, André CPLF and Rodrigues, Jose F},
  booktitle = {2018 IEEE Frontiers in Education Conference (FIE)},
  title     = {A comparative analysis of the automatic modeling of Learning Styles through Machine Learning techniques},
  year      = {2018},
  month     = {Oct},
  pages     = {1-8},
  abstract  = {This Research Full Paper introduces a machine learning methodology to automatically identify the learning style of students interacting with a Learning Management System. Studies in Cognitive Psychology and Pedagogy have already reported that each individual has a specific Learning Style, which describes her/his best means of perceiving and acquiring knowledge. The detection of the personal Learning Style of each student has long been made by using questionnaires; an analysis that demands too much effort, mainly in courses with hundreds of students. Therefore, the automatic modeling of learning styles has gained attention in the computing and education areas. This study compares different Machine Learning algorithms for the detection of students' Learning Styles. As such, a dataset is extracted from a real course in the Moodle learning platform. This course had 105 students interacting with 252 learning objects during 12 months. The learning styles were described using the classic model of Felder-Silverman. According to the experimental results using these data, a single machine learning algorithm was not able to induce models with predictive accuracy comparable to those from existing alternatives. However, when models from different algorithms were combined, it was possible to obtain a predictive accuracy superior to those reported in the related literature.},
  doi       = {10.1109/FIE.2018.8659191},
  issn      = {2377-634X},
  keywords  = {Learning Styles, Machine Learning, Learning Management Systems, Automatic Modeling, Education Technology},
}

@Article{spadon2019reconstructing,
  author       = {Gabriel Spadon and A. Carvalho and Jose F. Rodrigues-Jr and L. G. Alves},
  journaltitle = {Scientific Reports},
  title        = {Reconstructing commuters network using machine learning and urban indicators},
  doi          = {10.1038/s41598-019-48295-x},
  eprint       = {1908.03512},
  eprinttype   = {arXiv},
  issn         = {2045-2322},
  number       = {1},
  pages        = {11801},
  url          = {www.semanticscholar.org/paper/906276e0bd661576058118e121413e07fcc307ba},
  volume       = {9},
  abstract     = {Human mobility has a significant impact on several layers of society, from infrastructural planning and economics to the spread of diseases and crime. Representing the system as a complex network, in which nodes are assigned to regions (e.g., a city) and links indicate the flow of people between two of them, physics-inspired models have been proposed to quantify the number of people migrating from one city to the other. Despite the advances made by these models, our ability to predict the number of commuters and reconstruct mobility networks remains limited. Here, we propose an alternative approach using machine learning and 22 urban indicators to predict the flow of people and reconstruct the intercity commuters network. Our results reveal that predictions based on machine learning algorithms and urban indicators can reconstruct the commuters network with 90.4% of accuracy and describe 77.6% of the variance observed in the flow of people between cities. We also identify essential features to recover the network structure and the urban indicators mostly related to commuting patterns. As previously reported, distance plays a significant role in commuting, but other indicators, such as Gross Domestic Product (GDP) and unemployment rate, are also driven-forces for people to commute. We believe that our results shed new lights on the modeling of migration and reinforce the role of urban indicators on commuting patterns. Also, because link-prediction and network reconstruction are still open challenges in network science, our results have implications in other areas, like economics, social sciences, and biology, where node attributes can give us information about the existence of links connecting entities in the network.},
  journal      = {Scientific reports},
  pmid         = {31409862},
  publisher    = {Springer Science and Business Media LLC},
  venue        = {Scientific Reports},
  year         = {2019},
  keywords     = {Commuters Network, Machine Learning, Urban Indicators, Human Mobility, Network Reconstruction}
}

@Article{rodrigues2019patient,
  author     = {José F. Rodrigues and Gabriel Spadon and Bruno Brandoli and S. Amer-Yahia},
  journal    = {arXiv preprint arXiv:1909.04605},
  title      = {Patient trajectory prediction in the Mimic-III dataset, challenges and pitfalls},
  year       = {2019},
  abstract   = {Automated medical prognosis has gained interest as artificial intelligence evolves and the potential for computer-aided medicine becomes evident. Nevertheless, it is challenging to design an effective system that, given a patient's medical history, is able to predict probable future conditions. Previous works, mostly carried out over private datasets, have tackled the problem by using artificial neural network architectures that cannot deal with low-cardinality datasets, or by means of non-generalizable inference approaches. We introduce a Deep Learning architecture whose design results from an intensive experimental process. The final architecture is based on two parallel Minimal Gated Recurrent Unit networks working in bi-directional manner, which was extensively tested with the open-access Mimic-III dataset. Our results demonstrate significant improvements in automated medical prognosis, as measured with Recall@k. We summarize our experience as a set of relevant insights for the design of Deep Learning architectures. Our work improves the performance of computer-aided medicine and can serve as a guide in designing artificial neural networks used in prediction tasks.},
  eprint     = {1909.04605},
  eprinttype = {arXiv},
  url        = {www.semanticscholar.org/paper/5380983ed96622b94e65ac877f63f5735598f463},
  venue      = {arXiv.org},
keywords     = {Patient Trajectory Prediction, Deep Learning, Medical Prognosis, Mimic-III Dataset, Bidirectional Neural Networks}
}

@InProceedings{scabora2020enhancing,
  author    = {Scabora, Lucas C. and Spadon, Gabriel and Oliveira, Paulo H. and Rodrigues-Jr, Jose F. and Traina-Jr, Caetano},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
  title     = {Enhancing recursive graph querying on RDBMS with data clustering approaches},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {404–411},
  publisher = {Association for Computing Machinery},
  series    = {SAC '20},
  abstract  = {Recursive queries are one of the main mechanisms in Relational Database Management Systems to process topology-aware, or graph-like, queries. However, existing works focus only on optimizing the recursive query statements and processing, disregarding the potential physical arrangements that might improve performance. In this work, we propose to use an approach based on adjacent-list storage to physically organize the graph-like data aiming at both reducing the recursive query time and the number of I/O operations. By using Clustered Tables, we tied the adjacency list in chunks for (i) storing both vertex and edge tables together in a Combined Tables approach; and (ii) reordering the edge table with the Edge Clustered Table approach using 20% and 80% of the total adjacency list size. The clustered approaches enabled a faster recursive query processing (up to 22%) and a reduction of up to 61% in the number of page accesses when compared to the Conventional approach. When starting from multiple vertices, the Combined Tables approach achieved a query reduction time of up to 50% in the first join operation, and Edge Clustered Table 20% provided an overall time reduction of up to 20%. The results show that our physical design is effective and allows one to use recursive queries without adaptations.},
  doi       = {10.1145/3341105.3375770},
  isbn      = {9781450368667},
  keywords  = {Recursive Queries, Relational Database, Data Clustering, Adjacency List Storage, Query Optimization},
  location  = {Brno, Czech Republic},
  numpages  = {8},
  url       = {doi.org/10.1145/3341105.3375770},
}

@InProceedings{spadon2016health,
  author    = {Spadon, Gabriel and Correia, Ronaldo Celso Messias and Garcia, Rogério Eduardo and Olivete, Celso and Santos, Bruno Renan Gelako},
  booktitle = {2016 11th Iberian Conference on Information Systems and Technologies (CISTI)},
  title     = {Health information system for medical survey analysis},
  year      = {2016},
  month     = {June},
  pages     = {1-6},
  abstract  = {The process of data collection involves the organization of a group of questions, where its answers will be analyzed to obtain results. This process is faced with difficulty of standardization and obtaining accurate results, where usually the collect, storage and computation of results are manually realized. Several factors may cause unwanted results, like poorly completed forms, difficulty of interpretation of what was informed and disinterest of who fills it. Not all problems can be simply solved, but HIS (Health Information System) aids the process and data analysis, ensuring consistency and integrity. This work presents WebSISLapam, a web application to collect, organize and analyze data related to medical survey responses, supporting the creation and reuse of forms, questions and quantitative and qualitative variables.},
  doi       = {10.1109/CISTI.2016.7521568},
  keywords  = {Health Information System, Medical Survey Analysis, Data Collection, Web Application, e-Health},
}

@InProceedings{rocha2018internet,
  author    = {Rocha, João E. M. and Olivete, Celso and Gomes, Pedro H. A. and Garcia, Rogério E. and Correia, Ronaldo C. M. and de Souza, Gabriel Spadon and Eler, Danilo M.},
  booktitle = {Information Technology - New Generations},
  title     = {Internet-Based Education: A New Milestone for Formal Language and Automata Courses},
  year      = {2018},
  address   = {Cham},
  editor    = {Latifi, Shahram},
  pages     = {195-200},
  publisher = {Springer International Publishing},
  abstract  = {This paper aims at introducing a methodology focused on student-centered learning and aided by an educational collaborative and graphical tool. Through it, we enable students to interact with abstract topics as well as interact with each other. Our motivation was the lack of capability to represent knowledge and abstractions faced by students that work alone. In this regard, we present as result a tool to be used in the whole educational processes, together with a teaching-learning methodology that is described from multiple points of view.},
  isbn      = {978-3-319-77028-4},
  keywords  = {Internet-Based Education, Student-Centered Learning, Collaborative Tools, Formal Language, Automata Courses},
}

@InProceedings{rodrigues2020lig,
  author    = {Rodrigues, Jose F and Spadon, Gabriel and Brandoli, Bruno and Amer-Yahia, Sihem},
  booktitle = {2020 IEEE 33rd International Symposium on Computer-Based Medical Systems (CBMS)},
  title     = {Lig-Doctor: Real-World Clinical Prognosis using a Bi-Directional Neural Network},
  doi       = {10.1109/CBMS49503.2020.00113},
  pages     = {569-572},
  abstract  = {Automated medical prognosis has gained interest as artificial intelligence evolves and the potential for computer-aided medicine becomes evident. Nevertheless, it is challenging to design an effective system that, given a patient's medical history, can predict probable future conditions. Previous works have tackled the problem by using artificial neural network architectures that do not benefit from bi-directional temporal processing, or by utilizing non-generalizable inference approaches. Differently, we introduce a Deep Learning architecture whose design results from an intensive experimental process; our final architecture is based on two parallel Minimal Gated Recurrent Unit networks working in bi-directional manner, which was extensively tested with two real-world datasets. Our results demonstrate significant improvements in automated medical prognosis, as measured with metrics Precision@, Recall@, F1-Score, and AUC-ROC. We contribute with an architecture and with insights for the design of Deep Learning architectures.},
  issn      = {2372-9198},
  keywords     = {Clinical Prognosis, Neural Networks, Deep Learning, Patient Trajectory Prediction, Bidirectional Processing},
  month     = {July},
  year      = {2020},
}

@Article{rodrigues2021ligdoctor,
  author   = {Jose F. Rodrigues-Jr and Marco A. Gutierrez and Gabriel Spadon and Bruno Brandoli and Sihem Amer-Yahia},
  journal  = {Information Sciences},
  title    = {LIG-Doctor: Efficient patient trajectory prediction using bidirectional minimal gated-recurrent networks},
  year     = {2021},
  issn     = {0020-0255},
  pages    = {813-827},
  volume   = {545},
  abstract = {The interest for patient trajectory prediction, a sort of computer-aided medicine, has steadily increased with the pace of artificial intelligence innovation. Notwithstanding, the design of effective systems able to predict clinical outcomes based on the history of a patient is far from trivial. Works so far are based on neural architectures with low performance, especially when using low-cardinality datasets; alternatively, complex inference approaches are hard to reproduce and/or extrapolate as they are designed for very specific circumstances. We introduce LIG-Doctor, an artificial neural network architecture based on two Minimal Gated Recurrent Unit networks functioning in a bidirectional parallel manner, benefiting from temporal events both forward and backward. In comparison to state-of-the-art works, consistent improvements were achieved in prognosis prediction, as assessed with metrics Recall@k, Precision@k, F1-score, and AUC-ROC. Besides the detailed delineation of our architecture, a sequence of experiments is reported with insights that progressively guided design decisions to inspire future works on similar problems. Our results shall contribute to the improvement of computer-aided medicine and, more generally, to processes related to the design of neural network architectures.},
  doi      = {https://doi.org/10.1016/j.ins.2020.09.024},
  keywords = {Patient Trajectory Prediction, Bidirectional Minimal Gated-Recurrent Networks, Deep Learning, Medical Prognosis, Neural Network Architecture},
  url      = {https://www.sciencedirect.com/science/article/pii/S002002552030935X},
}

@Article{brandoli2021dropleaf,
  author   = {Bruno Brandoli and Gabriel Spadon and Travis Esau and Patrick Hennessy and Andre C.P.L. Carvalho and Sihem Amer-Yahia and Jose F. Rodrigues-Jr},
  journal  = {Computers and Electronics in Agriculture},
  title    = {DropLeaf: A precision farming smartphone tool for real-time quantification of pesticide application coverage},
  year     = {2021},
  issn     = {0168-1699},
  pages    = {105906},
  volume   = {180},
  abstract = {Pesticides have been heavily used in the cultivation of major crops, contributing to the increase of crop production over the past decades. However, in many cases their appropriate use and calibration of machines rely upon dated evaluation methodologies that cannot precisely estimate how well the pesticides’ are being applied to the crop. A few strategies have been proposed in former works, yet their elevated costs and low portability do not permit their wide spread adoption. This work introduces and experimentally assesses a novel tool that functions as a smartphone-based mobile application, named DropLeaf - Spraying Meter. Tests performed using DropLeaf demonstrated that, notwithstanding its simplicity, it can estimate the pesticide coverage with high precision. Our methodology is based on the development of custom image analysis software for real-time assessment of spraying deposition of water-sensitive papers. The proposed tool can be extensively used by farmers and agronomists carrying regular smartphones, improving the utilization of pesticides with well-being, ecological, and monetary advantages. DropLeaf can be easily used for spray drift assessment of different methods, including emerging unmanned aerial vehicle and smart sprayers.},
  doi      = {https://doi.org/10.1016/j.compag.2020.105906},
  keywords = {Precision Farming, Pesticide Application, Smartphone Tool, Image Analysis, Real-Time Assessment},
  url      = {https://www.sciencedirect.com/science/article/pii/S0168169920331112},
}

@InProceedings{scabora2021sharq,
  author    = {Scabora, Lucas C and Spadon, Gabriel and Cazzolato, Mirela T and Kaster, Daniel S and Traina, Agma JM and Rodrigues-Jr, Jose F and Traina-Jr, Caetano},
  booktitle = {Proceedings of the 36th Annual ACM Symposium on Applied Computing},
  title     = {SHARq: sharing recursive queries in relational databases},
  year      = {2021},
  pages     = {336-339},
  abstract  = {Processing navigational graph-like queries in relational databases requires executing several recursive join operations, which are computationally costly. However, when the need for graph-like queries arises, applications often execute a sequence of related queries in a single session. We argue that it is possible to reduce the total cost of a set of related queries, by expanding individual intermediate results and sharing them among multiple queries. SHARq is our framework that enables sharing intermediate results of the common graph-like queries Single-Source Shortest Paths (SSSP), Connected Components (CC), and PageRank (PR). Our solution prepares result tables expanded with additional columns to store partial results of graph-like query combinations, such as multiple SSSP, or a sequence of queries comprising SSSP, CC, and PR. Experimental results on 9 datasets show query speedups of up to ten times when combining multiple SSSP queries, and up to two times when combining SSSP, CC, and PR queries. The results reveal a significant reduction in the query time, providing timely results for analyses relying on multiple navigational graph-like queries.},
  doi       = {10.1145/3412841.3442078},
  url       = {www.semanticscholar.org/paper/4690dce7202de83debaf3598949776483920bb64},
  venue     = {ACM Symposium on Applied Computing},
keywords     = {Recursive Queries, Relational Databases, Graph-Like Queries, Query Optimization, SHARq}
}

@Article{spadon2021pay,
  author   = {Spadon, Gabriel and Hong, Shenda and Brandoli, Bruno and Matwin, Stan and Rodrigues-Jr, Jose F. and Sun, Jimeng},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {Pay Attention to Evolution: Time Series Forecasting With Deep Graph-Evolution Learning},
  year     = {2022},
  issn     = {1939-3539},
  month    = {Sep.},
  number   = {9},
  pages    = {5368-5384},
  volume   = {44},
  abstract = {Time-series forecasting is one of the most active research topics in artificial intelligence. It has the power to bring light to problems in several areas of knowledge, such as epidemiological studies, healthcare inference, and climate change analysis. Applications in real-world time series should consider two factors for achieving reliable predictions: modeling dynamic dependencies among multiple variables and adjusting the model's intrinsic hyperparameters. An open gap in the literature is that statistical and ensemble learning approaches systematically present lower predictive performance than deep learning methods. The existing applications consistently disregard the data sequence aspect entangled with multivariate data represented in more than one time series. Conversely, this work presents a novel neural network architecture for time-series forecasting that combines the power of graph evolution with deep recurrent learning on distinct data distributions, named after Recurrent Graph Evolution Neural Network (ReGENN). The idea is to infer multiple multivariate relationships between co-occurring time-series by assuming that the temporal data depends not only on inner variables and intra-temporal relationships (i.e., observations from itself) but also on outer variables and inter-temporal relationships (i.e., observations from other-selves). An extensive set of experiments was conducted comparing ReGENN with tens of ensemble methods and classical statistical ones. The results outperformed both statistical and ensemble-learning approaches, showing an improvement of 64.87 percent over the competing algorithms on the SARS-CoV-2 dataset of the renowned John Hopkins University for 188 countries simultaneously. For further validation, we tested our architecture in two other public datasets of different domains, the PhysioNet Computing in Cardiology Challenge 2012 and Brazilian Weather datasets. We also analyzed the Evolution Weights arising from the hidden layers of ReGENN to describe how the variables of the dataset interact with each other; and, as a result of looking at inter and intra-temporal relationships simultaneously, we concluded that time-series forecasting is majorly improved if paying attention to how multiple multivariate data synchronously evolve.},
  doi      = {10.1109/TPAMI.2021.3076155},
 keywords     = {Time Series Forecasting, Deep Learning, Graph Evolution, Recurrent Neural Networks, Multivariate Data}
}

@Article{brandoli2021aircraft,
  author         = {Brandoli, Bruno and de Geus, André R. and Souza, Jefferson R. and Spadon, Gabriel and Soares, Amilcar and Rodrigues, Jose F. and Komorowski, Jerzy and Matwin, Stan},
  journal        = {Sensors},
  title          = {Aircraft Fuselage Corrosion Detection Using Artificial Intelligence},
  year           = {2021},
  issn           = {1424-8220},
  number         = {12},
  volume         = {21},
  abstract       = {Corrosion identification and repair is a vital task in aircraft maintenance to ensure continued structural integrity. Regarding fuselage lap joints, typically, visual inspections are followed by non-destructive methodologies, which are time-consuming. The visual inspection of large areas suffers not only from subjectivity but also from the variable probability of corrosion detection, which is aggravated by the multiple layers used in fuselage construction. In this paper, we propose a methodology for automatic image-based corrosion detection of aircraft structures using deep neural networks. For machine learning, we use a dataset that consists of D-Sight Aircraft Inspection System (DAIS) images from different lap joints of Boeing and Airbus aircrafts. We also employ transfer learning to overcome the shortage of aircraft corrosion images. With precision of over 93%, we demonstrate that our approach detects corrosion with a precision comparable to that of trained operators, aiding to reduce the uncertainties related to operator fatigue or inadequate training. Our results indicate that our methodology can support specialists and engineers in corrosion monitoring in the aerospace industry, potentially contributing to the automation of condition-based maintenance protocols.},
  article-number = {4026},
  doi            = {10.3390/s21124026},
  keywords       = {Aircraft Corrosion Detection, Artificial Intelligence, Deep Neural Networks, Image-Based Detection, Transfer Learning},
  pubmedid       = {34207959},
  url            = {https://www.mdpi.com/1424-8220/21/12/4026},
}

@Article{oishi2021neural,
  author    = {Cassio M. Oishi and Fabio Vinícius Goes Amaral and Hugo L. França and William Hideki Nakata and Diego Alecsander de Aguiar and Gilmar Francisco de Oliveira Santos and Débora de Oliveira Medeiros and Gabriel Spadon and José Fernando Rodrigues Jr and José Mario Martínez and Lúcio Tunes Santos and D. S. Soares Filho},
  title     = {Neural Networks for Seismic Data Inversion},
  doi       = {10.33774/miir-2021-6pz3v},
  url       = {www.semanticscholar.org/paper/17c573d31e8c190a5c39ca6630a53c7f64c72ac2},
  abstract  = {Building a velocity model is essential in seismic exploration and is used at all stages, including acquisition, processing and interpretation of seismic data. Reconstructing a subsurface image from seismic wavefields recorded at the surface (seismograms) requires accurate knowledge of the propagation velocities between the recording location and the image location at depth. Estimation of velocity models can also be used as initial models to recursively generate high-resolution velocity models through optimization algorithms. Machine learning is a field of artificial intelligence that uses computational techniques to give systems the ability to learn from a large volume of data. In particular, neural networks have been developed to reconstruct subsurface parameters, i.e., the acoustic (compressional) wave velocity model, directly from raw seismic data. Using this principle as a starting point we will use two neural network approaches to solve the problem, where a GAN neural network and a ReGENN network will be used.},
  publisher = {Cambridge University Press (CUP)},
  year      = {2021},
  keywords     = {Neural Networks, Seismic Data Inversion, Velocity Model, Machine Learning, GAN}
}

@PhdThesis{souza2021cities,
  author     = {Souza, Gabriel Spadon de},
  school     = {Universidade de São Paulo},
  title      = {From Cities to Series: Complex Networks and Deep Learning for Improved Spatial and Temporal Analytics},
  year       = {2021},
  abstract   = {Graphs have often been used to answer questions about the interaction between real-world entities by taking advantage of their capacity to represent complex topologies. Complex networks are known to be graphs that capture such non-trivial topologies; they are able to represent human phenomena such as epidemic processes, the dynamics of populations, and the urbanization of cities. The investigation of complex networks has been extrapolated to many fields of science, with particular emphasis on computing techniques, including artificial intelligence. In such a case, the analysis of the interaction between entities of interest is transposed to the internal learning of algorithms, a paradigm whose investigation is able to expand the state of the art in Computer Science. By exploring this paradigm, this thesis puts together complex networks and machine learning techniques to improve the understanding of the human phenomena observed in pandemics, pendular migration, and street networks. Accordingly, we contribute with: (i) a new neural network architecture capable of modeling dynamic processes observed in spatial and temporal data with applications in epidemics propagation, weather forecasting, and patient monitoring in intensive care units; (ii) a machine-learning methodology for analyzing and predicting links in the scope of human mobility between all the cities of Brazil; and, (iii) techniques for identifying inconsistencies in the urban planning of cities while tracking the most influential vertices, with applications over Brazilian and worldwide cities. We obtained results sustained by sound evidence of advances to the state of the art in artificial intelligence, rigorous formalisms, and ample experimentation. Our findings rely upon real-world applications in a range of domains, demonstrating the applicability of our methodologies.},
  doi        = {10.48550/arXiv.2206.01176},
  eprint     = {2206.01176},
  eprinttype = {arXiv},
  keywords   = {Complex Networks, Deep Learning, Spatial Analytics, Temporal Analytics, Human Phenomena},
  url        = {www.semanticscholar.org/paper/4913ad2ca909ddbc740f3a5970786ae6bd2f0817},
  venue      = {arXiv.org},
}

@Article{spadon2022unfolding,
  author   = {Spadon, Gabriel and Ferreira, Martha D. and Soares, Amilcar and Matwin, Stan},
  journal  = {IEEE Access},
  title    = {Unfolding AIS Transmission Behavior for Vessel Movement Modeling on Noisy Data Leveraging Machine Learning},
  year     = {2023},
  issn     = {2169-3536},
  pages    = {18821-18837},
  volume   = {11},
  abstract = {The oceans are a source of an impressive mixture of complex data that could be used to uncover relationships yet to be discovered. Such data comes from the oceans and their surface, such as Automatic Identification System (AIS) messages used for tracking vessels’ trajectories. AIS messages are transmitted over radio or satellite at ideally periodic time intervals but vary irregularly over time. As such, this paper aims to model the AIS message transmission behavior through neural networks for forecasting upcoming AIS messages’ content from multiple vessels, particularly in a simultaneous approach despite messages’ temporal irregularities as outliers. We present a set of experiments comprising multiple algorithms for forecasting tasks with horizon sizes of varying lengths. Deep learning models (e.g., neural networks) revealed themselves to adequately preserve vessels’ spatial awareness regardless of temporal irregularity. We show how convolutional layers, feed-forward networks, and recurrent neural networks can improve such tasks by working together. Experimenting with short, medium, and large-sized sequences of messages, our model achieved  $6/37/38%  of the Relative Percentage Difference– the lower, the better, whereas we observed  92/45/96%  on the Elman’s RNN, 51/52/40%  on the GRU, and  129/98/61%  on the LSTM. These results support our model as a driver for improving the prediction of vessel routes when analyzing multiple vessels of diverging types simultaneously under temporally noise data.},
  doi      = {10.1109/ACCESS.2022.3197215},
  keywords     = {AIS Transmission Forecasting, Vessel Movement Modeling, Deep Learning, Temporal Irregularity, Neural Networks}
}

@Article{rodrigues2022cpap,
  author         = {Rodrigues, Jose F. and Bailly, Sebastien and Pepin, Jean-Louis and Goeuriot, Lorraine and Spadon, Gabriel and Amer-Yahia, Sihem},
  journal        = {Applied Sciences},
  title          = {CPAP Adherence Assessment via Gaussian Mixture Modeling of Telemonitored Apnea Therapy},
  year           = {2022},
  issn           = {2076-3417},
  number         = {15},
  volume         = {12},
  abstract       = {Sleep disorders pose serious cardiovascular threats if not treated effectively. However, adherence to Continuous Positive Airway Pressure (CPAP), the most recommended therapy, is known to be challenging to monitor. Telemonitored CPAP equipment has improved the follow-up of CPAP adherence (hours of use per night) by producing far larger amounts of data collected daily. The analysis of such data have relied on averaging the entire therapeutic history and interpreting it without a proper reference concerning the level of adherence. By contrast, we contribute with an unsupervised machine-learning methodology that (i) translates the adherence data to a scale of discrete numbers that hold correspondence to the most usual 30-day-long patterns as observed in a real-word database; (ii) avoids the loss of information aggregation problem by creating summaries of the time series that capture the dynamic nature of the everyday-use CPAP. Our experiments have detected eight particular adherence behaviors validated with information-oriented statistical criteria; we successfully applied them to the time series of a French hospital to produce summaries that reflect the adherence of any 30 days of interest. Our method can aid physicians in more precisely evaluating the therapy adherence, as well as fostering systems to alert of problems in the treatment automatically.},
  article-number = {7618},
  doi            = {10.3390/app12157618},
  keywords       = {CPAP Adherence, Sleep Disorders, Telemonitoring, Gaussian Mixture Modeling, Unsupervised Learning},
  url            = {www.mdpi.com/2076-3417/12/15/7618},
}

@Article{ferreira2022semi,
  author         = {Ferreira, Martha Dais and Spadon, Gabriel and Soares, Amilcar and Matwin, Stan},
  journal        = {Sensors},
  title          = {A Semi-Supervised Methodology for Fishing Activity Detection Using the Geometry behind the Trajectory of Multiple Vessels},
  year           = {2022},
  issn           = {1424-8220},
  number         = {16},
  volume         = {22},
  abstract       = {Automatic Identification System (AIS) messages are useful for tracking vessel activity across oceans worldwide using radio links and satellite transceivers. Such data play a significant role in tracking vessel activity and mapping mobility patterns such as those found during fishing activities. Accordingly, this paper proposes a geometric-driven semi-supervised approach for fishing activity detection from AIS data. Through the proposed methodology, it is shown how to explore the information included in the messages to extract features describing the geometry of the vessel route. To this end, we leverage the unsupervised nature of cluster analysis to label the trajectory geometry, highlighting changes in the vessel’s moving pattern, which tends to indicate fishing activity. The labels obtained by the proposed unsupervised approach are used to detect fishing activities, which we approach as a time-series classification task. We propose a solution using recurrent neural networks on AIS data streams with roughly 87% of the overall F-score on the whole trajectories of 50 different unseen fishing vessels. Such results are accompanied by a broad benchmark study assessing the performance of different Recurrent Neural Network (RNN) architectures. In conclusion, this work contributes by proposing a thorough process that includes data preparation, labeling, data modeling, and model validation. Therefore, we present a novel solution for mobility pattern detection that relies upon unfolding the geometry observed in the trajectory.},
  article-number = {6063},
  doi            = {10.3390/s22166063},
  keywords       = {Fishing Activity Detection, Semi-Supervised Learning, AIS Data, Trajectory Geometry, Recurrent Neural Networks},
  pubmedid       = {36015824},
  url            = {www.mdpi.com/1424-8220/22/16/6063},
}

@Article{spadon2024probabilistic,
  author     = {Spadon, Gabriel and Kumar, Jay and Eden, Derek and van Berkel, Josh and Foster, Tom and Soares, Amilcar and Fablet, Ronan and Matwin, Stan and Pelot, Ronald},
  journal    = {arXiv preprint arXiv:2310.18948},
  title      = {Multi-Path Long-Term Vessel Trajectories Forecasting with Probabilistic Feature Fusion for Problem Shifting},
  year       = {2024},
  abstract   = {This paper addresses the challenge of boosting the precision of multi-path long-term vessel trajectory forecasting on engineered sequences of Automatic Identification System (AIS) data using feature fusion for problem shifting. We have developed a deep auto-encoder model and a phased framework approach to predict the next 12 hours of vessel trajectories using 1 to 3 hours of AIS data as input. To this end, we fuse the spatiotemporal features from the AIS messages with probabilistic features engineered from historical AIS data referring to potential routes and destinations. As a result, we reduce the forecasting uncertainty by shifting the problem into a trajectory reconstruction problem. The probabilistic features have an F1-Score of approximately 85% and 75% for the vessel route and destination prediction, respectively. Under such circumstances, we achieved an R2 Score of over 98% with different layer structures and varying feature combinations; the high R2 Score is a natural outcome of the well-defined shipping lanes in the study region. However, our proposal stands out among competing approaches as it demonstrates the capability of complex decision-making during turnings and route selection. Furthermore, we have shown that our model achieves more accurate forecasting with average and median errors of 11km and 6km, respectively, a 25% improvement from the current state-of-the-art approaches. The resulting model from this proposal is deployed as part of a broader Decision Support System to safeguard whales by preventing the risk of vessel-whale collisions under the smartWhales initiative and acting on the Gulf of St. Lawrence in Atlantic Canada.},
  doi        = {doi.org/10.48550/arXiv.2310.18948},
  eprint     = {2310.18948},
  eprinttype = {arXiv},
  url        = {www.semanticscholar.org/paper/ddb6da0b0a60d8b54b7f740421170b0b287110e7},
keywords     = {Vessel Trajectory Forecasting, Probabilistic Feature Fusion, AIS Data, Deep Learning, Decision Support System}

}

@InProceedings{haranwala2023augmentation,
  author    = {J. Haranwala, Yaksh and Spadon, Gabriel and Renso, Chiara and Soares, Amilcar},
  booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on Methods for Enriched Mobility Data: Emerging Issues and Ethical Perspectives 2023},
  title     = {A Data Augmentation Algorithm for Trajectory Data},
  year      = {2023},
  address   = {New York, NY, USA},
  pages     = {25–29},
  publisher = {Association for Computing Machinery},
  series    = {EMODE '23},
  abstract  = {The growing prevalence of location-based devices has resulted in a significant abundance of location data from various tracking vendors. Nevertheless, a noticeable deficit exists regarding readily accessible, extensive, and publicly available datasets for research purposes, primarily due to privacy concerns and ownership constraints. There is a pressing need for expansive datasets to advance machine learning techniques in this domain. The absence of such resources currently represents a substantial hindrance to research progress in this field. Data augmentation is emerging as a popular technique to mitigate this issue in several domains. However, applying state-of-the-art techniques as-is proves challenging when dealing with trajectory data due to the intricate spatio-temporal dependencies inherent to such data. In this work, we propose a novel strategy for augmenting trajectory data that applies a geographical perturbation on trajectory points along a trajectory. Such a perturbation results in controlled changes in the raw trajectory and, consequently, causes changes in the trajectory feature space. We test our strategy in two trajectory datasets and show a performance improvement of approximately 20% when contrasted with the baseline. We believe this strategy will pave the way for a more comprehensive framework for trajectory data augmentation that can be used in fields where few labeled trajectory data are available for training machine learning models.},
  doi       = {10.1145/3615885.3628008},
  isbn      = {9798400703478},
  keywords  = {Data Augmentation, Trajectory Data, Machine Learning, Spatio-Temporal Dependencies, Geographical Perturbation},
  location  = {Hamburg, Germany},
  numpages  = {5},
  url       = {doi.org/10.1145/3615885.3628008},
}

@Article{song2024gravity,
  author     = {Ruixin Song and Gabriel Spadon and Ronald Pelot and S. Matwin and Amílcar Soares},
  journal    = {arXiv preprint arXiv:2401.13098},
  title      = {Enhancing Global Maritime Traffic Network Forecasting with Gravity-Inspired Deep Learning Models},
  year       = {2024},
  abstract   = {Aquatic non-indigenous species (NIS) pose significant threats to biodiversity, disrupting ecosystems and inflicting substantial economic damages across agriculture, forestry, and fisheries. Due to the fast growth of global trade and transportation networks, NIS has been introduced and spread unintentionally in new environments. This study develops a new physics-informed model to forecast maritime shipping traffic between port regions worldwide. The predicted information provided by these models, in turn, is used as input for risk assessment of NIS spread through transportation networks to evaluate the capability of our solution. Inspired by the gravity model for international trades, our model considers various factors that influence the likelihood and impact of vessel activities, such as shipping flux density, distance between ports, trade flow, and centrality measures of transportation hubs. Accordingly, this paper introduces transformers to gravity models to rebuild the short- and long-term dependencies that make the risk analysis feasible. Thus, we introduce a physics-inspired framework that achieves an 89% binary accuracy for existing and non-existing trajectories and an 84.8% accuracy for the number of vessels flowing between key port areas, representing more than 10% improvement over the traditional deep-gravity model. Along these lines, this research contributes to a better understanding of NIS risk assessment. It allows policymakers, conservationists, and stakeholders to prioritize management actions by identifying high-risk invasion pathways. Besides, our model is versatile and can include new data sources, making it suitable for assessing international vessel traffic flow in a changing global landscape.},
  doi        = {10.48550/arXiv.2401.13098},
  eprint     = {2401.13098},
  eprinttype = {arXiv},
  keywords   = {Maritime Traffic Forecasting, Gravity Model, Deep Learning, Non-Indigenous Species, Risk Assessment},
  url        = {www.semanticscholar.org/paper/551711583c6325c33b91e67f81b07fd97c917e96},
  venue      = {arXiv.org},
}

@Article{alam2024enhancing,
  author       = {M. Alam and Gabriel Spadon and Mohammad Etemad and Luis Torgo and E. Milios},
  journal      = {Ocean Engineering},
  title        = {Enhancing short-term vessel trajectory prediction with clustering for heterogeneous and multi-modal movement patterns},
  year         = {2024},
  issn         = {0029-8018},
  pages        = {118303},
  volume       = {308},
  abstract     = {Predicting vessel trajectories is crucial for enhancing situational awareness and preventing collisions at sea. However, achieving accurate and efficient predictions is challenging due to the heterogeneity in vessel movement patterns and changes in vessel mobility modes during voyages. To address this, we propose a new approach that uses historical AIS data to cluster route patterns for each vessel type, thereby improving prediction accuracy. By training machine learning algorithms to focus only on similar vessel types, this approach can better predict individual vessel mobility patterns. This approach offers computational advantages by using a relatively small set of trajectories from the nearest cluster of a selected vessel. Both spatial and course attributes are considered to determine the nearest cluster, while engineered features capture changes in vessel mobility modes. Using an AIS dataset from UTM Zone 10N (US West Coast), we achieved distance errors of 370m, 742m, and 1.2km for horizons 10, 20, and 30 min, respectively, using the Random Forest algorithm for short-term trajectory prediction (<= 30 min) with the last 1-hour trajectory of selected vessels as input.},
  doi          = {10.1016/j.oceaneng.2024.118303},
  journaltitle = {Ocean Engineering},
  keywords     = {Vessel Trajectory Prediction, Clustering, Heterogeneous Movement Patterns, AIS Data, Short-Term Prediction},
  publisher    = {Elsevier BV},
  url          = {www.semanticscholar.org/paper/5e511627da21b2d0b957576f7e10e63c1a5c0475},
  venue        = {Ocean Engineering},
}

@Comment{jabref-meta: databaseType:bibtex;}
