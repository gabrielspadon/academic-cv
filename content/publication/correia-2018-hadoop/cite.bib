@article{correia2018hadoop,
 abstract = {For a long time, data has been treated as a general problem because it just represents fractions of an event without any relevant purpose. However, the last decade has been just about information and how to get it. Seeking meaning in data and trying to solve scalability problems, many frameworks have been developed to improve data storage and its analysis. As a framework, Hadoop was presented as a powerful tool to deal with large amounts of data. However, it still causes doubts about how to deal with its deployment and if there is any reliable method to compare the performance of distinct Hadoop clusters. This paper presents a methodology based on benchmark analysis to guide the Hadoop cluster deployment. The experiments employed The Apache Hadoop and the Hadoop distributions of Cloudera, Hortonworks, and MapR, analyzing the architectures on local and on clouding—using centralized and geographically distributed servers. The results show the methodology can be dynamically applied on a reliable comparison among different architectures. Additionally, the study suggests that the knowledge acquired can be used to improve the data analysis process by understanding the Hadoop architecture.},
 article-number = {131},
 author = {Correia, Ronaldo Celso Messias and Spadon, Gabriel and De Andrade Gomes, Pedro Henrique and Eler, Danilo Medeiros and Garcia, Rogério Eduardo and Olivete Junior, Celso},
 doi = {10.3390/info9060131},
 issn = {2078-2489},
 journal = {Information},
 keywords = {Hadoop Cluster, Deployment Methodology, Benchmark Analysis, Data Scalability, Distributed Computing},
 month = {May},
 number = {6},
 pages = {131},
 publisher = {MDPI AG},
 title = {Hadoop Cluster Deployment: A Methodological Approach},
 url = {www.mdpi.com/2078-2489/9/6/131},
 volume = {9},
 year = {2018}
}
